{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78d6d65b",
   "metadata": {},
   "source": [
    "# Image Preprocessing Pipeline – CIFAR-10\n",
    "\n",
    "This notebook demonstrates a custom image preprocessing pipeline for color images.\n",
    "Each transformation is applied step-by-step, visualized, and analyzed by printing\n",
    "image shapes and pixel value ranges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7febf35",
   "metadata": {},
   "source": [
    "!pip install torch torchvision opencv-python matplotlib numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abee216",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8676f935",
   "metadata": {},
   "source": [
    "dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "img1, _ = dataset[0]\n",
    "img2, _ = dataset[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03b63e5",
   "metadata": {},
   "source": [
    "def show_image(img, title):\n",
    "    img_np = img.permute(1, 2, 0).numpy()\n",
    "    print(f\"{title} → Shape: {img.shape}, Pixel Range: [{img.min():.3f}, {img.max():.3f}]\")\n",
    "    plt.imshow(img_np, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d45cd14",
   "metadata": {},
   "source": [
    "resize = transforms.Resize((64, 64))\n",
    "img1_r = resize(img1)\n",
    "img2_r = resize(img2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf05689",
   "metadata": {},
   "source": [
    "gray = transforms.Grayscale(num_output_channels=1)\n",
    "img1_g = gray(img1_r)\n",
    "img2_g = gray(img2_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453be11b",
   "metadata": {},
   "source": [
    "rotate = transforms.RandomRotation(30)\n",
    "img1_rot = rotate(img1_g)\n",
    "img2_rot = rotate(img2_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718f6112",
   "metadata": {},
   "source": [
    "flip = transforms.RandomHorizontalFlip(p=1.0)\n",
    "img1_f = flip(img1_rot)\n",
    "img2_f = flip(img2_rot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291bc681",
   "metadata": {},
   "source": [
    "normalize = transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "img1_n = normalize(img1_f)\n",
    "img2_n = normalize(img2_f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1382f6d0",
   "metadata": {},
   "source": [
    "def sharpen(img):\n",
    "    img_np = img.squeeze().numpy()\n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                       [-1, 5, -1],\n",
    "                       [0, -1, 0]])\n",
    "    sharp = cv2.filter2D(img_np, -1, kernel)\n",
    "    return torch.tensor(sharp).unsqueeze(0)\n",
    "\n",
    "img1_s = sharpen(img1_n)\n",
    "img2_s = sharpen(img2_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a68168",
   "metadata": {},
   "source": [
    "steps = [\n",
    "    (\"Resized\", img1_r, img2_r),\n",
    "    (\"Grayscale\", img1_g, img2_g),\n",
    "    (\"Rotated\", img1_rot, img2_rot),\n",
    "    (\"Flipped\", img1_f, img2_f),\n",
    "    (\"Normalized\", img1_n, img2_n),\n",
    "    (\"Sharpened\", img1_s, img2_s)\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "for i, (title, a, b) in enumerate(steps):\n",
    "    plt.subplot(len(steps), 2, i*2 + 1)\n",
    "    show_image(a, f\"{title} - Image 1\")\n",
    "    plt.subplot(len(steps), 2, i*2 + 2)\n",
    "    show_image(b, f\"{title} - Image 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966155e7",
   "metadata": {},
   "source": [
    "final_tensor = torch.stack([img1_s, img2_s])\n",
    "print(\"Final Tensor Shape:\", final_tensor.shape)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
